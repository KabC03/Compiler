//Generated by:generate_tokeniser_enum.py
#include "tokens.h++"

const string tokens[] = {
	"char",   //0 :: TOK_KEYWORD_CHAR
	"int",    //1 :: TOK_KEYWORD_INT
	"float",  //2 :: TOK_KEYWORD_FLOAT
	"ptr",    //3 :: TOK_KEYWORD_PTR
	"=",      //4 :: TOK_SYMBOL_ASSIGNMENT
	"while",  //5 :: TOK_KEYWORD_WHILE
	"if",     //6 :: TOK_KEYWORD_IF
	"elif",   //7 :: TOK_KEYWORD_ELIF
	"else",   //8 :: TOK_KEYWORD_ELSE
	"return", //9 :: TOK_KEYWORD_RETURN
	"+",      //10 :: TOK_SYMBOL_PLUS
	"-",      //11 :: TOK_SYMBOL_MINUS
	"*",      //12 :: TOK_SYMBOL_MUL
	"/",      //13 :: TOK_SYMBOL_DIV
	"==",     //14 :: TOK_SYMBOL_EQUALS
	"!=",     //15 :: TOK_SYMBOL_NEQ
	">=",     //16 :: TOK_SYMBOL_GREQ
	"<=",     //17 :: TOK_SYMBOL_LEQ
	">",      //18 :: TOK_SYMBOL_GREATER
	"<",      //19 :: TOK_SYMBOL_LESS
	",",      //20 :: TOK_SYMBOL_COMMA
	";",      //21 :: TOK_SEMICOLON
	"#",      //22 :: TOK_SYMBOL_REFERENCE
	"@",      //23 :: TOK_SYMBOL_DEREFERENCE
	"(",      //24 :: TOK_BRACE_OPEN_PAREN
	")",      //25 :: TOK_BRACE_CLOSE_PAREN
	"{",      //26 :: TOK_BRACE_OPEN_CURLEY
	"}",      //27 :: TOK_BRACE_CLOSE_CURLEY
};
